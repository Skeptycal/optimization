# Optimization
A collection of the state-of-the-art Optimization Algorithms.
	
- Mathematical foundations of optimization: Optimization problems, local/global minima, optimality conditions, convexity
- Unconstrained optimization: gradient descent, conjugate gradients, Newton's method, quasi-Newton methods
- Constrained optimization: Karush-Kuhn-Tucker conditions, Lagrange multipliers
- Linear programming: Simplex method, interior point methods

![Build Status](https://travis-ci.org/tompollard/phd_thesis_markdown.svg?branch=master)](https://travis-ci.org/tompollard/phd_thesis_markdown)  

Directores:
1. Shortest Path as Linear Programming
2. Proves of the convexity or concavity of mathematical functions
3. Neuronal Network
4. Logistic Regression
   ![Result](https://github.com/computeVision/optimization/blob/master/ocs_hw4/docs/graph.png)
5. Shortest Path in a Labyrinth


## Installation
  Python 2.7 and Numpy

## Usage
  These are simple python scripts. Can be executed in a shell. 

## History

This file started with LinkerScript Parser v0.0 and tracks the feature of this tool.
Each line will describe a single addition/removement/change and adhere to the following format:

`<Author> <Type> : <Textual_description_without_linebreak>`

Authors (so far):

  * PL   Peter Lorenz

Type:

  * \+ Addition
  * \- Removement
  * \# Modification
  * \~ Fix
  * \! Misc.
  * (very significant entries should be in upper case and prefixed with "-----" )

Table of changes:

  * `PL + The initial setup is done. Version 0.0`
  * todo add changes

## Credits

  * Peter Lorenz.

## License

GNU General Public License v3.0
